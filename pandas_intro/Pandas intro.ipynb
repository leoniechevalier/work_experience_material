{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a data frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ones  zeros\n",
      "0   1.0    0.0\n",
      "1   1.0    0.0\n",
      "2   1.0    0.0\n",
      "3   1.0    0.0\n",
      "4   1.0    0.0\n",
      "5   1.0    0.0\n",
      "6   1.0    0.0\n",
      "7   1.0    0.0\n",
      "8   1.0    0.0\n",
      "9   1.0    0.0\n"
     ]
    }
   ],
   "source": [
    "#when writing a data frame from scratch pandas will take data in the form of a dictionary\n",
    "\n",
    "data ={'ones':np.ones(10),\n",
    "       'zeros':np.zeros(10)\n",
    "}\n",
    "\n",
    "#making a data frame from scratch\n",
    "#start with any data or colum names that you want to input\n",
    "data_frame = pd.DataFrame(data,columns=['ones','zeros'])\n",
    "\n",
    "print(data_frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ones  zeros  new_colum\n",
      "0   1.0    0.0        2.0\n",
      "1   1.0    0.0        2.0\n",
      "2   1.0    0.0        2.0\n",
      "3   1.0    0.0        2.0\n",
      "4   1.0    0.0        2.0\n",
      "5   1.0    0.0        2.0\n",
      "6   1.0    0.0        2.0\n",
      "7   1.0    0.0        2.0\n",
      "8   1.0    0.0        2.0\n",
      "9   1.0    0.0        2.0\n"
     ]
    }
   ],
   "source": [
    "#to add additional colums afterwards define them as follows:\n",
    "#simply define your new colum anme and assign data to it\n",
    "\n",
    "data_frame['new_colum']=np.ones(10)+1\n",
    "\n",
    "print (data_frame)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Fruit   Shape\n",
      "0      Apple   round\n",
      "1     Banana    long\n",
      "2  Pineapple  spikey\n"
     ]
    }
   ],
   "source": [
    "#creating a pd.DataFrame from lists\n",
    "\n",
    "#your lists of data\n",
    "fruit= ('Apple','Banana','Pineapple')\n",
    "shape=('round','long','spikey')\n",
    "\n",
    "\n",
    "\n",
    "#define keys\n",
    "list_keys=('Fruit','Shape')\n",
    "#create master list of data\n",
    "list_data=[fruit,shape]\n",
    "#zip data with coresponding keys\n",
    "zipped_data = list(zip(list_keys,list_data))\n",
    "#make into a dictionary\n",
    "df_input_data = dict(zipped_data)\n",
    "\n",
    "#read in as data frame\n",
    "df_fruit = pd.DataFrame(df_input_data)\n",
    "\n",
    "print(df_fruit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fruit     Shape  number\n",
      "0  orange     round     1.0\n",
      "1    Kiwi       NaN     NaN\n",
      "2  Grapes  roundish   100.5\n",
      "       Fruit     Shape  number\n",
      "0      Apple     round     1.0\n",
      "1     Banana      long     5.0\n",
      "2  Pineapple    spikey     NaN\n",
      "3     orange     round     1.0\n",
      "4       Kiwi       NaN     NaN\n",
      "5     Grapes  roundish   100.5\n"
     ]
    }
   ],
   "source": [
    "#adding a new colum with nans\n",
    "\n",
    "df_fruit['number']=[1,5,np.nan]\n",
    "\n",
    "#print(df_fruit)\n",
    "\n",
    "#adding a new row of 'oranges'\n",
    "fruit2={'Fruit':['orange','Kiwi','Grapes'],\n",
    "       'Shape':['round',np.nan,'roundish'],\n",
    "       'number':[1,np.nan,100.5]}\n",
    "df_fruit2=pd.DataFrame(fruit2,columns=(['Fruit','Shape','number']))\n",
    "print df_fruit2\n",
    "\n",
    "something_else=df_fruit.append(df_fruit2, ignore_index=True)\n",
    "\n",
    "#when appending one df into another there is some truble with how to access the merged frame\n",
    "# in this case the command df_fruit.ix[3] will not work!!\n",
    "print something_else\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and writing files\n",
    "\n",
    "If you have an exsisting file or want to write our table into a file you can easily do this with pandas\n",
    "\n",
    "# pandas file types\n",
    "\n",
    "pandas reads a wide variety of file types (csv,txt and alsp pickled files). \n",
    "It is even possible to execute sql queries! (not showing that today)\n",
    "\n",
    "It does NOT read fits files! \n",
    "\n",
    "To read / write data define what type you want (i.e pd.read_XYZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the data file\n",
    "\n",
    "filename='cereal.csv'\n",
    "df=pd.read_csv(filename)\n",
    "\n",
    "#other read functions include\n",
    "    #pd.read_table\n",
    "    #pd.read_text\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Other options for the various read methods include what deliminators to use.\n",
    "These can be defined with 'sep =' when reading in the file.\n",
    "                ','-comma\n",
    "                ' '- whitespace\n",
    "                '\\t'-tap\n",
    "For excell files/workbooks you can define the sheet_name that you want to read in  \n",
    "If you dont want the total file you can define the number of rows to read in\n",
    "Also define whether or not you are reading in the header (header=)or rename the colums \n",
    "Excluding the header means you colums will not be named!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# retriving data frame information\n",
    "\n",
    "a full list / cheat sheet regarding pandas is availible with this material!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 77 entries, 0 to 76\n",
      "Data columns (total 16 columns):\n",
      "name        77 non-null object\n",
      "mfr         77 non-null object\n",
      "type        77 non-null object\n",
      "calories    77 non-null int64\n",
      "protein     77 non-null int64\n",
      "fat         77 non-null int64\n",
      "sodium      77 non-null int64\n",
      "fiber       77 non-null float64\n",
      "carbo       77 non-null float64\n",
      "sugars      77 non-null int64\n",
      "potass      77 non-null int64\n",
      "vitamins    77 non-null int64\n",
      "shelf       77 non-null int64\n",
      "weight      77 non-null float64\n",
      "cups        77 non-null float64\n",
      "rating      77 non-null float64\n",
      "dtypes: float64(5), int64(8), object(3)\n",
      "memory usage: 9.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#basic info\n",
    "#comment and uncomment to have a look at the various methods\n",
    "\n",
    "\n",
    "\n",
    "df.info() # basic information regarding your colums and number of objects in each column (will flag nans)\n",
    "\n",
    "#df.count() # number coun in each colum with theyr respective keys\n",
    "\n",
    "#df.shape # shape of your data frame (as usual)\n",
    "\n",
    "#df.columns # names of your columns\n",
    "\n",
    "#df.index # unique index list\n",
    "\n",
    "#df.keys() #list of your keys to access column data\n",
    "\n",
    "#df.describe() # returns basic info for each column (count,unique etc.)\n",
    "\n",
    "#df.idxmin() #minimum or maximim index value (doens't work with example data set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name        100% Natural Bran\n",
      "mfr                         Q\n",
      "type                        C\n",
      "calories                  120\n",
      "protein                     3\n",
      "fat                         5\n",
      "sodium                     15\n",
      "fiber                       2\n",
      "carbo                       8\n",
      "sugars                      8\n",
      "potass                    135\n",
      "vitamins                    0\n",
      "shelf                       3\n",
      "weight                      1\n",
      "cups                        1\n",
      "rating                33.9837\n",
      "Name: 1, dtype: object\n",
      "                   name mfr type  calories  protein  fat  sodium  fiber  \\\n",
      "76  Wheaties Honey Gold   G    C       110        2    1     200    1.0   \n",
      "\n",
      "    carbo  sugars  potass  vitamins  shelf  weight  cups     rating  \n",
      "76   16.0       8      60        25      1     1.0  0.75  36.187559  \n",
      "0                                  100% Bran\n",
      "1                          100% Natural Bran\n",
      "2                                   All-Bran\n",
      "3                  All-Bran with Extra Fiber\n",
      "4                             Almond Delight\n",
      "5                    Apple Cinnamon Cheerios\n",
      "6                                Apple Jacks\n",
      "7                                    Basic 4\n",
      "8                                  Bran Chex\n",
      "9                                Bran Flakes\n",
      "10                              Cap'n'Crunch\n",
      "11                                  Cheerios\n",
      "12                     Cinnamon Toast Crunch\n",
      "13                                  Clusters\n",
      "14                               Cocoa Puffs\n",
      "15                                 Corn Chex\n",
      "16                               Corn Flakes\n",
      "17                                 Corn Pops\n",
      "18                             Count Chocula\n",
      "19                        Cracklin' Oat Bran\n",
      "20                    Cream of Wheat (Quick)\n",
      "21                                   Crispix\n",
      "22                    Crispy Wheat & Raisins\n",
      "23                               Double Chex\n",
      "24                               Froot Loops\n",
      "25                            Frosted Flakes\n",
      "26                       Frosted Mini-Wheats\n",
      "27    Fruit & Fibre Dates; Walnuts; and Oats\n",
      "28                             Fruitful Bran\n",
      "29                            Fruity Pebbles\n",
      "                       ...                  \n",
      "47                      Multi-Grain Cheerios\n",
      "48                          Nut&Honey Crunch\n",
      "49                 Nutri-Grain Almond-Raisin\n",
      "50                         Nutri-grain Wheat\n",
      "51                      Oatmeal Raisin Crisp\n",
      "52                     Post Nat. Raisin Bran\n",
      "53                                Product 19\n",
      "54                               Puffed Rice\n",
      "55                              Puffed Wheat\n",
      "56                        Quaker Oat Squares\n",
      "57                            Quaker Oatmeal\n",
      "58                               Raisin Bran\n",
      "59                           Raisin Nut Bran\n",
      "60                            Raisin Squares\n",
      "61                                 Rice Chex\n",
      "62                             Rice Krispies\n",
      "63                            Shredded Wheat\n",
      "64                    Shredded Wheat 'n'Bran\n",
      "65                 Shredded Wheat spoon size\n",
      "66                                    Smacks\n",
      "67                                 Special K\n",
      "68                   Strawberry Fruit Wheats\n",
      "69                         Total Corn Flakes\n",
      "70                         Total Raisin Bran\n",
      "71                         Total Whole Grain\n",
      "72                                   Triples\n",
      "73                                      Trix\n",
      "74                                Wheat Chex\n",
      "75                                  Wheaties\n",
      "76                       Wheaties Honey Gold\n",
      "Name: name, dtype: object\n",
      "100% Natural Bran\n"
     ]
    }
   ],
   "source": [
    "#selecting rows\n",
    "\n",
    "#by label i.e the index number (unique identifier assosiated with a dataentry)\n",
    "print(df.ix[1])\n",
    "\n",
    "#by position\n",
    "print (df.iloc[1])\n",
    "\n",
    "#slicing\n",
    "print (df[76:])\n",
    "\n",
    "#selecting colums\n",
    "\n",
    "#by keys\n",
    "print (df['name'])\n",
    "\n",
    "# or select in both rows and colums\n",
    "\n",
    "print (df.ix[1,'name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.33\n",
      "1    1.00\n",
      "2    0.33\n",
      "3    0.50\n",
      "4    0.75\n",
      "Name: cups, dtype: float64\n",
      "72    0.75\n",
      "73    1.00\n",
      "74    0.67\n",
      "75    1.00\n",
      "76    0.75\n",
      "Name: cups, dtype: float64\n",
      "                         name mfr type  calories  protein  fat  sodium  fiber  \\\n",
      "33                 Grape-Nuts   P    C       110        3    0     170    3.0   \n",
      "34         Great Grains Pecan   P    C       120        3    3      75    3.0   \n",
      "2                    All-Bran   K    C        70        4    1     260    9.0   \n",
      "0                   100% Bran   N    C        70        4    1     130   10.0   \n",
      "3   All-Bran with Extra Fiber   K    C        50        4    0     140   14.0   \n",
      "\n",
      "    carbo  sugars  potass  vitamins  shelf  weight  cups     rating  \n",
      "33   17.0       3      90        25      3     1.0  0.25  53.371007  \n",
      "34   13.0       4     100        25      3     1.0  0.33  45.811716  \n",
      "2     7.0       5     320        25      3     1.0  0.33  59.425505  \n",
      "0     5.0       6     280        25      3     1.0  0.33  68.402973  \n",
      "3     8.0       0     330        25      3     1.0  0.50  93.704912  \n",
      "        name mfr type  calories  protein  fat  sodium  fiber  carbo  sugars  \\\n",
      "0  100% Bran   N    C        70        4    1     130   10.0    5.0       6   \n",
      "\n",
      "   potass  vitamins  shelf  weight  cups     rating  \n",
      "0     280        25      3     1.0  0.33  68.402973  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/astroconda/lib/python2.7/site-packages/ipykernel/__main__.py:10: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "/anaconda/envs/astroconda/lib/python2.7/site-packages/ipykernel/__main__.py:13: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "# for a brief look at some of your data call head or tail (also works well if previously you sorted your data frame!)\n",
    "\n",
    "#will return you the top 5 elements in your data frame\n",
    "print (df['cups'].head())\n",
    "\n",
    "#will return the last 5 elements in your data frame\n",
    "print (df['cups'].tail())\n",
    "\n",
    "# an example of sorting  and using the tail method\n",
    "print df.sort(columns=['cups','sugars']).head()\n",
    "\n",
    "# if you want to access sorted data say the fourth entry in you r sorted table use iloc not ix!!!\n",
    "print df.sort(columns=['cups','sugars']).iloc[[3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      9\n",
       "1     17\n",
       "2      8\n",
       "3     25\n",
       "4     14\n",
       "5     23\n",
       "6     11\n",
       "7      7\n",
       "8      9\n",
       "9     11\n",
       "10    12\n",
       "11     8\n",
       "12    21\n",
       "13     8\n",
       "14    11\n",
       "15     9\n",
       "16    11\n",
       "17     9\n",
       "18    13\n",
       "19    18\n",
       "20    22\n",
       "21     7\n",
       "22    22\n",
       "23    11\n",
       "24    11\n",
       "25    14\n",
       "26    19\n",
       "27    38\n",
       "28    13\n",
       "29    14\n",
       "      ..\n",
       "47    20\n",
       "48    16\n",
       "49    25\n",
       "50    17\n",
       "51    20\n",
       "52    21\n",
       "53    10\n",
       "54    11\n",
       "55    12\n",
       "56    18\n",
       "57    14\n",
       "58    11\n",
       "59    15\n",
       "60    14\n",
       "61     9\n",
       "62    13\n",
       "63    14\n",
       "64    22\n",
       "65    25\n",
       "66     6\n",
       "67     9\n",
       "68    23\n",
       "69    17\n",
       "70    17\n",
       "71    17\n",
       "72     7\n",
       "73     4\n",
       "74    10\n",
       "75     8\n",
       "76    19\n",
       "Name: name, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one way to write a function to count he lenght of the name of each cereal\n",
    "def count_string(data):\n",
    "    lenght =[]\n",
    "    for i in data:\n",
    "        lenght.append(len(i))\n",
    "    return lenght\n",
    "\n",
    "name_lenght=count_string(df['name'])\n",
    "\n",
    "\n",
    "#alternative much shorter version !!\n",
    "f = lambda x: len(x)\n",
    "df['name'].apply(f)\n",
    "\n",
    "#if you wanted to apply his not only to the name version but you wanted to know the length of any object in your data frame :\n",
    "\n",
    "#df.applymap(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# removing nans and replacing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(name      Nutri-Grain Almond-Raisin\n",
      "sugars                            7\n",
      "rating                      40.6923\n",
      "Name: 49, dtype: object, name      Nutri-grain Wheat\n",
      "sugars                    2\n",
      "rating              59.6428\n",
      "Name: 0, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "#at this stage you can try using any of the other kaggle datasets in the folder to have a play around\n",
    "#just make sure you adjust all the column names accordingly!\n",
    "\n",
    "filename='cereal2.csv'\n",
    "\n",
    "df=pd.read_csv(filename, nrows=50, usecols=['name','sugars','rating'])\n",
    "\n",
    "#if you skip rows and do not define a set of colum names it will assign the values it finds in the first row...\n",
    "#other method for this specific example is to use df.keys()[x] to determine the relevant names\n",
    "df_extra_rows=pd.read_csv(filename,skiprows=51,usecols=[0,9,15], names=['name','sugars','rating'])\n",
    "\n",
    "#check that we didn't download a row twice\n",
    "\n",
    "print(df.ix[49],df_extra_rows.ix[0]) #using an index of -1 won't work\n",
    "\n",
    "df_columns=pd.read_csv(filename,usecols=[1,11])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sugars</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Grape Nuts Flakes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.076897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name  sugars     rating\n",
       "32  Grape Nuts Flakes     NaN  52.076897"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find out where there are nan's\n",
    "# returns you how many null objects\n",
    "#df.info()\n",
    "\n",
    "# THIS WILL NOT WORK!! as np.nan==np.nan will return False!!!\n",
    "#df['sugars']==np.nan\n",
    "\n",
    "#However this will!! to filter out nans use the np.isnan function\n",
    "#df['sugars'].apply(np.isnan)\n",
    "\n",
    "#this way you can find the idex of each nan value \n",
    "#np.where(df['sugars'].apply(np.isnan))\n",
    "\n",
    "#if you know the location of the nan use df.loc[x]\n",
    "# df['sugars'].ix[np.where(df['sugars'].apply(np.isnan))]=(1,1,1,1,1)\n",
    "df[(df['sugars'].isnull()) & (df.rating > 50)]\n",
    "#alternatively use the pd.fillna function\n",
    "#just select what filler you want for you nan's\n",
    "\n",
    "# df.fillna(('nothing to see here'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merging data frames\n",
    "\n",
    "a number of data frames have been created for you above. Using the merge and concat function in pandas try stitching them back together.\n",
    "(start with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function merge in module pandas.tools.merge:\n",
      "\n",
      "merge(left, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=True, indicator=False)\n",
      "    Merge DataFrame objects by performing a database-style join operation by\n",
      "    columns or indexes.\n",
      "    \n",
      "    If joining columns on columns, the DataFrame indexes *will be\n",
      "    ignored*. Otherwise if joining indexes on indexes or indexes on a column or\n",
      "    columns, the index will be passed on.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    left : DataFrame\n",
      "    right : DataFrame\n",
      "    how : {'left', 'right', 'outer', 'inner'}, default 'inner'\n",
      "        * left: use only keys from left frame (SQL: left outer join)\n",
      "        * right: use only keys from right frame (SQL: right outer join)\n",
      "        * outer: use union of keys from both frames (SQL: full outer join)\n",
      "        * inner: use intersection of keys from both frames (SQL: inner join)\n",
      "    on : label or list\n",
      "        Field names to join on. Must be found in both DataFrames. If on is\n",
      "        None and not merging on indexes, then it merges on the intersection of\n",
      "        the columns by default.\n",
      "    left_on : label or list, or array-like\n",
      "        Field names to join on in left DataFrame. Can be a vector or list of\n",
      "        vectors of the length of the DataFrame to use a particular vector as\n",
      "        the join key instead of columns\n",
      "    right_on : label or list, or array-like\n",
      "        Field names to join on in right DataFrame or vector/list of vectors per\n",
      "        left_on docs\n",
      "    left_index : boolean, default False\n",
      "        Use the index from the left DataFrame as the join key(s). If it is a\n",
      "        MultiIndex, the number of keys in the other DataFrame (either the index\n",
      "        or a number of columns) must match the number of levels\n",
      "    right_index : boolean, default False\n",
      "        Use the index from the right DataFrame as the join key. Same caveats as\n",
      "        left_index\n",
      "    sort : boolean, default False\n",
      "        Sort the join keys lexicographically in the result DataFrame\n",
      "    suffixes : 2-length sequence (tuple, list, ...)\n",
      "        Suffix to apply to overlapping column names in the left and right\n",
      "        side, respectively\n",
      "    copy : boolean, default True\n",
      "        If False, do not copy data unnecessarily\n",
      "    indicator : boolean or string, default False\n",
      "        If True, adds a column to output DataFrame called \"_merge\" with\n",
      "        information on the source of each row.\n",
      "        If string, column with information on source of each row will be added to\n",
      "        output DataFrame, and column will be named value of string.\n",
      "        Information column is Categorical-type and takes on a value of \"left_only\"\n",
      "        for observations whose merge key only appears in 'left' DataFrame,\n",
      "        \"right_only\" for observations whose merge key only appears in 'right'\n",
      "        DataFrame, and \"both\" if the observation's merge key is found in both.\n",
      "    \n",
      "        .. versionadded:: 0.17.0\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    \n",
      "    >>> A              >>> B\n",
      "        lkey value         rkey value\n",
      "    0   foo  1         0   foo  5\n",
      "    1   bar  2         1   bar  6\n",
      "    2   baz  3         2   qux  7\n",
      "    3   foo  4         3   bar  8\n",
      "    \n",
      "    >>> A.merge(B, left_on='lkey', right_on='rkey', how='outer')\n",
      "       lkey  value_x  rkey  value_y\n",
      "    0  foo   1        foo   5\n",
      "    1  foo   4        foo   5\n",
      "    2  bar   2        bar   6\n",
      "    3  bar   2        bar   8\n",
      "    4  baz   3        NaN   NaN\n",
      "    5  NaN   NaN      qux   7\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    merged : DataFrame\n",
      "        The output type will the be same as 'left', if it is a subclass\n",
      "        of DataFrame.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use the merge function on the various data frames above\n",
    "\n",
    "help(pd.merge)\n",
    "\n",
    "#df_merged="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function concat in module pandas.tools.merge:\n",
      "\n",
      "concat(objs, axis=0, join='outer', join_axes=None, ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, copy=True)\n",
      "    Concatenate pandas objects along a particular axis with optional set logic\n",
      "    along the other axes. Can also add a layer of hierarchical indexing on the\n",
      "    concatenation axis, which may be useful if the labels are the same (or\n",
      "    overlapping) on the passed axis number\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    objs : a sequence or mapping of Series, DataFrame, or Panel objects\n",
      "        If a dict is passed, the sorted keys will be used as the `keys`\n",
      "        argument, unless it is passed, in which case the values will be\n",
      "        selected (see below). Any None objects will be dropped silently unless\n",
      "        they are all None in which case a ValueError will be raised\n",
      "    axis : {0, 1, ...}, default 0\n",
      "        The axis to concatenate along\n",
      "    join : {'inner', 'outer'}, default 'outer'\n",
      "        How to handle indexes on other axis(es)\n",
      "    join_axes : list of Index objects\n",
      "        Specific indexes to use for the other n - 1 axes instead of performing\n",
      "        inner/outer set logic\n",
      "    verify_integrity : boolean, default False\n",
      "        Check whether the new concatenated axis contains duplicates. This can\n",
      "        be very expensive relative to the actual data concatenation\n",
      "    keys : sequence, default None\n",
      "        If multiple levels passed, should contain tuples. Construct\n",
      "        hierarchical index using the passed keys as the outermost level\n",
      "    levels : list of sequences, default None\n",
      "        Specific levels (unique values) to use for constructing a\n",
      "        MultiIndex. Otherwise they will be inferred from the keys\n",
      "    names : list, default None\n",
      "        Names for the levels in the resulting hierarchical index\n",
      "    ignore_index : boolean, default False\n",
      "        If True, do not use the index values along the concatenation axis. The\n",
      "        resulting axis will be labeled 0, ..., n - 1. This is useful if you are\n",
      "        concatenating objects where the concatenation axis does not have\n",
      "        meaningful indexing information. Note the index values on the other\n",
      "        axes are still respected in the join.\n",
      "    copy : boolean, default True\n",
      "        If False, do not copy data unnecessarily\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The keys, levels, and names arguments are all optional\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    concatenated : type of objects\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use the merge function on the various data frames above\n",
    "\n",
    "help(pd.concat)\n",
    "\n",
    "#df_concat="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a new colum using the apply function\n",
    "df['name_length']=df['name'].apply(f)\n",
    "df.keys()\n",
    "#overwriting colums\n",
    "df['name_length']=df['name_length']+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method to_csv in module pandas.core.frame:\n",
      "\n",
      "to_csv(self, path_or_buf=None, sep=',', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, mode='w', encoding=None, compression=None, quoting=None, quotechar='\"', line_terminator='\\n', chunksize=None, tupleize_cols=False, date_format=None, doublequote=True, escapechar=None, decimal='.', **kwds) unbound pandas.core.frame.DataFrame method\n",
      "    Write DataFrame to a comma-separated values (csv) file\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    path_or_buf : string or file handle, default None\n",
      "        File path or object, if None is provided the result is returned as\n",
      "        a string.\n",
      "    sep : character, default ','\n",
      "        Field delimiter for the output file.\n",
      "    na_rep : string, default ''\n",
      "        Missing data representation\n",
      "    float_format : string, default None\n",
      "        Format string for floating point numbers\n",
      "    columns : sequence, optional\n",
      "        Columns to write\n",
      "    header : boolean or list of string, default True\n",
      "        Write out column names. If a list of string is given it is assumed\n",
      "        to be aliases for the column names\n",
      "    index : boolean, default True\n",
      "        Write row names (index)\n",
      "    index_label : string or sequence, or False, default None\n",
      "        Column label for index column(s) if desired. If None is given, and\n",
      "        `header` and `index` are True, then the index names are used. A\n",
      "        sequence should be given if the DataFrame uses MultiIndex.  If\n",
      "        False do not print fields for index names. Use index_label=False\n",
      "        for easier importing in R\n",
      "    nanRep : None\n",
      "        deprecated, use na_rep\n",
      "    mode : str\n",
      "        Python write mode, default 'w'\n",
      "    encoding : string, optional\n",
      "        A string representing the encoding to use in the output file,\n",
      "        defaults to 'ascii' on Python 2 and 'utf-8' on Python 3.\n",
      "    compression : string, optional\n",
      "        a string representing the compression to use in the output file,\n",
      "        allowed values are 'gzip', 'bz2', 'xz',\n",
      "        only used when the first argument is a filename\n",
      "    line_terminator : string, default '\\n'\n",
      "        The newline character or character sequence to use in the output\n",
      "        file\n",
      "    quoting : optional constant from csv module\n",
      "        defaults to csv.QUOTE_MINIMAL\n",
      "    quotechar : string (length 1), default '\"'\n",
      "        character used to quote fields\n",
      "    doublequote : boolean, default True\n",
      "        Control quoting of `quotechar` inside a field\n",
      "    escapechar : string (length 1), default None\n",
      "        character used to escape `sep` and `quotechar` when appropriate\n",
      "    chunksize : int or None\n",
      "        rows to write at a time\n",
      "    tupleize_cols : boolean, default False\n",
      "        write multi_index columns as a list of tuples (if True)\n",
      "        or new (expanded format) if False)\n",
      "    date_format : string, default None\n",
      "        Format string for datetime objects\n",
      "    decimal: string, default '.'\n",
      "        Character recognized as decimal separator. E.g. use ',' for\n",
      "        European data\n",
      "    \n",
      "        .. versionadded:: 0.16.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#similar to reading in files you can write into all file formats using the pd.to_xyz command\n",
    "#pandas can even write to latex files !!!!!!!\n",
    "\n",
    "help(pd.DataFrame.to_csv)\n",
    "\n",
    "df.to_csv('merged_csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
